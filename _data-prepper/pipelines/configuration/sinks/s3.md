---
layout: default
title: s3
parent: 下沉
grand_parent: 管道
nav_order: 55
---

# S3

这`s3` 水槽将一批事件保存到[亚马逊简单存储服务（Amazon S3）](https://aws.amazon.com/s3/) 对象。

## 用法

以下示例创建了配置S3水槽的管道。它包含用于自定义事件和大小阈值的其他选项，管道发送记录事件并设置编解码器类型`ndjson`：

```
pipeline:
  ...
  sink:
    - s3:
        aws:
          region: us-east-1
          sts_role_arn: arn:aws:iam::123456789012:role/Data-Prepper
          sts_header_overrides:
        max_retries: 5
        bucket:
          name: bucket_name
          object_key:
            path_prefix: my-elb/%{yyyy}/%{MM}/%{dd}/
        threshold:
          event_count: 2000
          maximum_size: 50mb
          event_collect_timeout: 15s
        codec:
          ndjson:
        buffer_type: in_memory
```

## 配置

自定义时使用以下选项`s3` 下沉。

选项| 必需的| 类型| 描述
：--- | ：--- | ：--- | ：---
`bucket` | 是的| 细绳| 检索数据然后存储的对象。这`name` 必须匹配对象存储的名称。
`codec` | 是的| [缓冲区类型](#buffer-type) | 确定缓冲区类型。
`aws` | 是的| AWS| AWS配置。看[AWS](#aws) 了解更多信息。
`threshold` | 是的| [临界点](#threshold-configuration) | 配置何时将对象写入S3。
`object_key` | 不| 设置`path_prefix` 和`file_pattern` 对象存储。默认为S3对象`events-%{yyyy-MM-dd'T'hh-mm-ss}` 在水桶的根目录中找到。
`compression` | 不| 细绳| 适用的压缩算法：`none`，，，，`gzip`， 或者`snappy`。默认为`none`。
`buffer_type` | 不| [缓冲区类型](#buffer-type) | 确定缓冲区类型。
`max_retries` | 不| 整数| 将数据摄入S3时，单个请求应重试的最大次数。默认为`5`。

## AWS

选项| 必需的| 类型| 描述
：--- | ：--- | ：--- | ：---
`region` | 不| 细绳| 用于凭证的AWS区域。默认为[标准SDK行为以确定该区域](https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/region-selection.html)。
`sts_role_arn` | 不| 细绳| AWS安全令牌服务（AWS STS）角色要担任亚马逊SQ和Amazon S3的请求。默认为`null`，将使用[凭证的标准SDK行为](https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/credentials.html)。
`sts_header_overrides` | 不| 地图| 标头的地图覆盖了IAM角色为接收器插件所假定的。
`sts_external_id` | 不| 细绳| 来自AWS STS的假设请求的外部ID。


## 阈值配置

使用以下选项设置摄入阈值`s3` 下沉。

选项| 必需的| 类型| 描述
：--- | ：--- | ：--- | ：---
`event_count` | 是的| 整数| S3存储桶可以摄入的最大事件数量。
`maximum_size` | 是的| 细绳| 压缩后S3桶可以摄入的最大字节数。默认为`50mb`。
`event_collect_timeout` | 是的| 细绳| 设置在摄入之前收集事件的时间段。所有值都是代表持续时间的字符串，要么是ISO_8601符号字符串，例如`PT20.345S`，或一个简单的符号，例如`60s` 或者`1500ms`。


## 缓冲区类型

`buffer_type` 是一种可选的配置，它在将它们冲入S3存储桶中之前暂时记录了存储的事件。默认值是`in_memory`。使用以下选项之一：

- `in_memory`：将记录存储在内存中。
- `local_file`：将记录冲入计算机上的文件中。
- `multipart`：使用[S3多部分上传](https://docs.aws.amazon.com/AmazonS3/latest/userguide/mpuoverview.html)。每10 MB被写为一部分。

## 对象密钥配置

选项| 必需的| 类型| 描述
：--- | ：--- | ：--- | ：---
`path_prefix` | 是的| 细绳| S3密钥前缀使用路径。接受日期-时间格式。例如，您可以使用`%{yyyy}/%{MM}/%{dd}/%{HH}/` 在S3中创建小时文件夹。默认情况下，事件写入水桶的根。


## 编解码器

这`codec` 确定如何`s3` 源格式数据写入每个S3对象。

### AVRO编解码器

这`avro` 编解码器将事件写为[Apache Avro](https://avro.apache.org/) 文档。

由于AVRO需要一个模式，因此您可以自己定义架构，或者数据预珀将自动生成架构。
通常，您应该定义自己的模式，因为它将最准确地反映您的需求。

我们建议您使您的Avro领域使用空[联盟](https://avro.apache.org/docs/current/specification/#unions)。
没有零联合，必须存在每个字段，否则数据将无法写入水槽。
如果您可以确定每个事件都有一个给定的字段，则可以使其非-无效。

当您提供自己的AVRO模式时，该模式定义了数据的最终结构。
因此，在最终目的地中不包含任何未映射在ARVO架构中的任何传入事件中的任何额外值。
避免自定义Arvo模式与`include_keys` 或者`exclude_keys` 接收器配置，数据预先不允许使用`include_keys` 或者`exclude_keys` 使用自定义模式。

如果数据统一，则您可以自动生成模式。
自动生成的模式基于编解码器收到的第一个事件。
该架构将仅包含此事件的键。
因此，您必须在所有事件中都有所有键，以使自动生成的模式生成工作模式。
自动生成的模式使所有字段都可无效。
使用水槽`include_keys` 和`exclude_keys` 配置以控制自动中包含哪些数据-生成的模式。


选项| 必需的| 类型| 描述
：--- | ：--- | ：--- | ：---
`schema` | 是的| 细绳| avro[模式声明](https://avro.apache.org/docs/current/specification/#schema-declaration)。如果不需要`auto_schema` 设置为true。
`auto_schema` | 不| 布尔| 设置为`true`，自动生成avro[模式声明](https://avro.apache.org/docs/current/specification/#schema-declaration) 从第一个事件开始。

 
### NDJSON编解码器

这`ndjson` 编解码器将每行作为JSON对象写入。

这`ndjson` 编解码器不采用任何配置。


### JSON编解码器

这`json` 编解码器在一个大JSON文件中写入事件。
每个事件都写入JSON数组中的对象。


选项| 必需的| 类型| 描述
：--- | ：--- | ：--- | ：---
`key_name` | 不| 细绳| JSON阵列的钥匙名称。默认这是`events`。


### 镶木编解码器

这`parquet` 编解码器将事件写入镶木木文件中。
使用Parquet编解码器时，设置`buffer_type` 到`in_memory`。

Parquet编解码器使用AVRO模式编写数据。
由于Parquet需要AVRO架构，因此您可以自己定义模式，或者数据预珀将自动生成架构。
但是，我们通常建议您定义自己的架构，以便它可以最好地满足您的需求。

有关AVRO模式和建议的详细信息，请参阅[AVRO编解码器](#avro-codec) 文档。


选项| 必需的| 类型| 描述
：--- | ：--- | ：--- | ：---
`schema` | 是的| 细绳| avro[模式声明](https://avro.apache.org/docs/current/specification/#schema-declaration)。如果不需要`auto_schema` 设置为true。
`auto_schema` | 不| 布尔| 设置为`true`，自动生成avro[模式声明](https://avro.apache.org/docs/current/specification/#schema-declaration) 从第一个事件开始。


