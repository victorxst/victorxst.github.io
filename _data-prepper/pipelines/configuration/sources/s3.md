---
layout: default
title: S3来源
parent: 来源
grand_parent: 管道
nav_order: 20
---

# S3来源

`s3` 是一个源插件，可读取事件[亚马逊简单存储服务（Amazon S3）](https://aws.amazon.com/s3/) 对象。它需要一个[亚马逊简单队列服务（Amazon SQS）](https://aws.amazon.com/sqs/) 接收的队列[S3事件通知](https://docs.aws.amazon.com/AmazonS3/latest/userguide/NotificationHowTo.html)。在配置Amazon SQS之后，`s3` 来源从Amazon SQS接收消息。当SQS消息指示创建了S3对象时`s3` 源加载S3对象，然后使用配置的[编解码器](#codec)。您还可以配置`s3` 使用的来源[亚马逊S3选择](https://docs.aws.amazon.com/AmazonS3/latest/userguide/selecting-content-from-objects.html) 而不是对解析S3对象的数据预备。

## IAM许可

为了使用`s3` 来源，配置您的AWS身份和访问管理（IAM）权限，以授予数据预先访问Amazon S3。您可以使用类似于以下JSON配置的配置：

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "s3-access",
            "Effect": "Allow",
            "Action": [
              "s3:GetObject",
              "s3:ListBucket",
              "s3:DeleteObject"
            ],
            "Resource": "arn:aws:s3:::<YOUR-BUCKET>/*"
        },
        {
            "Sid": "sqs-access",
            "Effect": "Allow",
            "Action": [
                "sqs:DeleteMessage",
                "sqs:ReceiveMessage"
            ],
            "Resource": "arn:aws:sqs:<YOUR-REGION>:<123456789012>:<YOUR-SQS-QUEUE>"
        },
        {
            "Sid": "kms-access",
            "Effect": "Allow",
            "Action": "kms:Decrypt",
            "Resource": "arn:aws:kms:<YOUR-REGION>:<123456789012>:key/<YOUR-KMS-KEY>"
        }
    ]
}
```

如果您的S3对象或Amazon SQS队列不使用[AWS密钥管理服务（AWS KMS）](https://aws.amazon.com/kms/)， 去除`kms:Decrypt` 允许。

## 叉-帐户S3访问<a Name ="s3_bucket_ownership"> </a>

当数据PEPPPER从S3存储桶中获取数据时，它会使用
[水桶所有者条件](https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucket-owner-condition.html)。
默认情况下，Data Prepper期望S3存储桶由拥有相关SQS队列的同一存储器拥有。
当不提供SQ时，Data Prepper使用Amazon资源名称（ARN）`aws` 配置。

如果您打算从多个S3存储桶中摄入数据，但是每个存储桶都与其他S3帐户关联，则需要配置数据预先检查以检查交叉-帐户S3访问，根据以下条件：

- 如果您希望从属于SQS队列以外的帐户的所有S3存储库，请设置`default_bucket_owner` 到“存储账户持有人”的帐户ID。
- 如果您的S3存储桶在多个帐户中，请使用`bucket_owners` 地图。

在下面的示例中，SQS队列归帐户所有`000000000000`。SQS队列包含来自两个S3存储桶的数据：`my-bucket-01` 和`my-bucket-02`。
因为`my-bucket-01` 由`123456789012` 和`my-bucket-02` 由`999999999999`， 这`bucket_owners` 地图调用两个存储桶所有者均具有其帐户ID，如以下配置所示：

```
s3:
  sqs:
      queue_url: "https://sqs.us-east-1.amazonaws.com/000000000000/MyQueue"
  bucket_owners:
    my-bucket-01: 123456789012
    my-bucket-02: 999999999999
```

你可以两者都使用`bucket_owners` 和`default_bucket_owner` 一起。

## 配置

您可以使用以下选项来配置`s3` 来源。

选项| 必需的| 类型| 描述
：--- | ：--- | ：--- | ：---
`notification_type` | 是的| 细绳| 必须是`sqs`。
`notification_source` | 不| 细绳| 确定SQS收到的通知。必须是`s3` 或者`eventbridge`。`s3` 表示直接从Amazon S3发送到Amazon SQS或从Amazon S3到Amazon Simple Notification Service（Amazon SNS）到Amazon SQS的通知。`eventbridge` 代表通知[Amazon Eventbridge](https://aws.amazon.com/eventbridge/) 和[亚马逊安全湖](https://aws.amazon.com/security-lake/)。默认为`s3`。
`compression` | 不| 细绳| 适用的压缩算法：`none`，，，，`gzip`， 或者`automatic`。默认为`none`。
`codec` | 是的| 编解码器| 这[编解码器](#codec) 申请。
`sqs` | 是的| SQS| SQS配置。看[SQS](#sqs) 了解更多信息。
`aws` | 是的| AWS| AWS配置。看[AWS](#aws) 了解更多信息。
`on_error` | 不| 细绳| 确定如何处理Amazon SQS中的错误。可以是`retain_messages` 或者`delete_messages`。`retain_messages` 将消息留在Amazon SQS队列中，并试图再次发送消息。建议死亡-字母队列。`delete_messages` 删除消息失败。默认为`retain_messages`。
buffer_timeout| 不| 期间| 允许在超时之前将事件写入数据预备缓冲区的时间。在设定的时间内，Amazon S3源无法写入缓冲区的任何事件都将被丢弃。默认为`10s`。
`records_to_accumulate` | 不| 整数| 写入缓冲区之前积累的消息数量。默认为`100`。
`metadata_root_key` | 不| 细绳| 为每个事件添加S3元数据的基本键。元数据包含每个S3对象的键和存储桶。默认为`s3/`。
`disable_bucket_ownership_validation` | 不| 布尔| 什么时候`true`，S3源没有试图验证该存储桶归预期的帐户所有。预期帐户是拥有Amazon SQS队列的同一帐户。默认为`false`。
`acknowledgments` | 不| 布尔| 什么时候`true`，启用`s3` 接收的来源[结尾-到-结束致谢]({{site.url}}{{site.baseurl}}/data-prepper/pipelines/pipelines#end-to-end-acknowledgments) 当通过OpenSearch水槽收到事件时。
`s3_select` | 不| [S3_SELECT](#s3_select) | Amazon S3选择配置。
`scan` | 不| [扫描](#scan) | S3扫描配置。
`delete_s3_objects_on_read` | 不| 布尔| 什么时候`true`，S3扫描试图在所有接收器成功地承认S3对象的所有事件后删除S3对象。`acknowledgments` 删除S3对象时应启用。默认为`false`。


## SQS

以下参数允许您配置Amazon SQS的使用量`s3` 源插件。

选项| 必需的| 类型| 描述
：--- | ：--- | ：--- | ：---
`queue_url` | 是的| 细绳| 接收消息的Amazon SQS队列的URL。
`maximum_messages` | 不| 整数| 在任何单个请求中，从Amazon SQS队列接收的最大消息数。默认为`10`。
`visibility_timeout` | 不| 期间| 可视性超时，适用于从Amazon SQS队列读取的消息。这应该设置为数据预先读取批次中所有S3对象的时间。默认为`30s`。
`wait_time` | 不| 期间| 等待在Amazon SQS API上进行长时间投票的时间。默认为`20s`。
`poll_delay` | 不| 期间| 在阅读和处理一批Amazon SQS消息和随后的请求之间放置了一个延迟。默认为`0s`。


## AWS

选项| 必需的| 类型| 描述
：--- | ：--- | ：--- | ：---
`region` | 不| 细绳| 用于凭证的AWS区域。默认为[标准SDK行为以确定该区域](https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/region-selection.html)。
`sts_role_arn` | 不| 细绳| AWS安全令牌服务（AWS STS）角色要担任亚马逊SQ和Amazon S3的请求。默认为`null`，将使用[凭证的标准SDK行为](https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/credentials.html)。
`aws_sts_header_overrides` | 不| 地图| 标头的地图覆盖了IAM角色为接收器插件所假定的。

## 编解码器

这`codec` 确定如何`s3` 源解析每个Amazon S3对象。为了提高和更有效的性能，您可以使用[编解码器组合]({{site.url}}{{site.baseurl}}/data-prepper/common-use-cases/codec-processor-combinations/) 与某些处理器。

### `newline` 编解码器

这`newline` 编解码器将每行解析为一个日志事件。这对于大多数应用程序日志都是理想的选择，因为每个事件每行解析。它也可以适用于在每行上具有单个JSON对象的S3对象，与[parse_json]({{site.url}}{{site.baseurl}}/data-prepper/pipelines/configuration/processors/parse-json/) 处理器以解析每一行。

使用以下选项配置`newline` 编解码器。

选项| 必需的| 类型| 描述
：--- | :--- |:--------| ：---
`skip_lines` | 不| 整数| 创建事件之前要跳过的行数。您可以使用此配置来跳过通用的标题行。默认为`0`。
`header_destination` | 不| 细绳| 将分配给S3对象的标头线的键值。如果指定了此选项，则每个事件将包含一个`header_destination` 场地。

### JSON编解码器

这`json` 编解码器将每个S3对象从JSON数组中解析为单个JSON对象，然后为数组中的每个对象创建一个数据Prepper日志事件。

### CSV编解码器

这`csv` 编解码器在逗号中解析对象-分开值（CSV）格式，每行都会产生数据预先日志事件。使用以下选项配置`csv` 编解码器。

选项| 必需的| 类型| 描述
:--- |:---------|：------------| ：---
`delimiter` | 是的| 整数| 分隔线分隔列。默认为`,`。
`quote_character` | 是的| 细绳| 该字符用作CSV数据的文本预选赛。默认为`"`。
`header` | 不| 字符串列表| 包含用于解析CSV数据的列名称的标题。
`detect_header` | 不| 布尔| Amazon S3对象的第一行是否应解释为标题。默认为`true`。




## 使用`s3_select` 与`s3` 来源<a name ="s3_select"> </a>

配置时`s3_select` 要解析Amazon S3对象，请使用以下选项：

选项| 必需的| 类型| 描述
:--- |:-----------------------|：------------| ：---
`expression` | 是的，当使用时`s3_select` | 细绳| 用来查询对象的表达式。直接地图[表达](https://docs.aws.amazon.com/AmazonS3/latest/API/API_SelectObjectContent.html#AmazonS3-SelectObjectContent-request-Expression) 财产。
`expression_type` | 不| 细绳| 提供的表达式的类型。默认值是`SQL`。直接地图[表达式类型](https://docs.aws.amazon.com/AmazonS3/latest/API/API_SelectObjectContent.html#AmazonS3-SelectObjectContent-request-ExpressionType)。
`input_serialization` | 是的，当使用时`s3_select` | 细绳| 提供S3选择文件格式。Amazon S3使用此格式将对象数据解析为记录，并仅返回与指定的SQL表达式匹配的记录。或许`csv`，，，，`json`， 或者`parquet`。
`compression_type` | 不| 细绳| 指定对象的压缩格式。直接地图[压缩类型](https://docs.aws.amazon.com/AmazonS3/latest/API/API_InputSerialization.html#AmazonS3-Type-InputSerialization-CompressionType)。
`csv` | 不| [CSV](#s3_select_csv) | 提供用于处理CSV数据的CSV配置。
`json` | 不| [JSON](#s3_select_json) | 提供用于处理JSON数据的JSON配置。

### csv <a name ="s3_select_csv"> </a>

将以下选项与`csv` 配置`s3_select` 确定应如何格式化的CSV文件。

这些选项将直接映射到S3选择中的选项[csvinput](https://docs.aws.amazon.com/AmazonS3/latest/API/API_CSVInput.html) 数据类型。

选项| 必需的| 类型| 描述
:--- |:---------|：------------| ：---
`file_header_info` | 不| 细绳| 描述输入的第一行。直接地图[fileheaderinfo](https://docs.aws.amazon.com/AmazonS3/latest/API/API_CSVInput.html#AmazonS3-Type-CSVInput-FileHeaderInfo) 财产。
`quote_escape` | 不| 细绳| 一个单个字符用于逃脱已经逃脱的值中的引号。直接地图[Quoteescapecharacter](https://docs.aws.amazon.com/AmazonS3/latest/API/API_CSVInput.html#AmazonS3-Type-CSVInput-QuoteEscapeCharacter) 财产。
`comments` | 不| 细绳| 一个用于指示该行在该行开始时的字符时，应忽略一行。直接地图[评论](https://docs.aws.amazon.com/AmazonS3/latest/API/API_CSVInput.html#AmazonS3-Type-CSVInput-Comments) 财产。

#### json <a name ="s3_select_json"> </a>

将以下选项与`json` 为了`s3_select` 要确定S3如何选择“ JSON文件”过程。

选项| 必需的| 类型| 描述
：--- | ：--- | ：--- | ：---
`type` | 不| 细绳| JSON数组的类型。可能是`DOCUMENT` 或者`LINES`。直接地图[类型](https://docs.aws.amazon.com/AmazonS3/latest/API/API_JSONInput.html#AmazonS3-Type-JSONInput-Type) 财产。

## 使用`scan` 与`s3` 来源<a name ="scan"> </a>
以下参数允许您扫描S3对象。所有选项都可以在存储级级别配置。

选项| 必需的| 类型| 描述
：--- | ：--- | ：--- | ：---
`start_time` | 不| 细绳| 给定后修改对象的开始扫描对象的时间`start_time`。这应该跟随[ISO LocalDateTime](https://docs.oracle.com/javase/8/docs/api/java/time/format/DateTimeFormatter.html#ISO_LOCAL_DATE_TIME) 例如，格式`023-01-23T10:00:00`。如果`end_time` 与`start_time`，所有对象之后`start_time` 和之前`end_time` 将被处理。`start_time` 和`range` 不能一起使用。
`end_time` | 不| 细绳| 在给定后不会扫描任何物体的时间`end_time`。这应该跟随[ISO LocalDateTime](https://docs.oracle.com/javase/8/docs/api/java/time/format/DateTimeFormatter.html#ISO_LOCAL_DATE_TIME) 例如，格式`023-01-23T10:00:00`。如果`start_time` 与`end_time`，所有对象之后`start_time` 和之前`end_time` 将被处理。`end_time` 和`range` 不能一起使用。
`range` | 不| 细绳| 从所有存储桶中扫描对象的时间范围。支持ISO_8601符号字符串，例如`PT20.345S` 或者`PT15M`，和符号字符串几秒钟（`60s`）和毫秒（`1600ms`）。`start_time` 和`end_time` 不能与`range`。范围`P12H` 扫描从管道开始的最后12个小时内修改的所有对象。
`buckets` | 是的| 列表| 的列表[水桶](#bucket) 扫描。
`scheduling` | 不| 列表| 用于在所有存储桶上安排定期扫描的配置。`start_time`，，，，`end_time` 和`range` 如果配置了调度，则无法使用。

### 桶

选项| 必需的| 类型| 描述
：--- | :--- |:-----| ：---
`bucket` | 是的| 地图| 为每个存储桶提供选项。

您可以配置以下选项[桶](#bucket) 环境。

选项| 必需的| 类型| 描述
：--- | ：--- | ：--- | ：---
`name` | 是的| 细绳| 代表S3存储桶名的字符串要扫描。
`filter` | 不| [筛选](#filter) | 提供过滤器配置。
`start_time` | 不| 细绳| 给定后修改对象的开始扫描对象的时间`start_time`。这应该跟随[ISO LocalDateTime](https://docs.oracle.com/javase/8/docs/api/java/time/format/DateTimeFormatter.html#ISO_LOCAL_DATE_TIME) 例如，格式`023-01-23T10:00:00`。如果`end_time` 与`start_time`，所有对象之后`start_time` 和之前`end_time` 将被处理。`start_time` 和`range` 不能一起使用。这将覆盖`start_time` 在[扫描](#scan) 等级。
`end_time` | 不| 细绳| 在给定后不会扫描任何物体的时间`end_time`。这应该跟随[ISO LocalDateTime](https://docs.oracle.com/javase/8/docs/api/java/time/format/DateTimeFormatter.html#ISO_LOCAL_DATE_TIME) 例如，格式`023-01-23T10:00:00`。如果`start_time` 与`end_time`，所有对象之后`start_time` 和之前`end_time` 将被处理。这覆盖了`end_time` 在[扫描](#scan) 等级。
`range` | 不| 细绳| 从所有存储桶中扫描对象的时间范围。支持ISO_8601符号字符串，例如`PT20.345S` 或者`PT15M`，和符号字符串几秒钟（`60s`）和毫秒（`1600ms`）。`start_time` 和`end_time` 不能与`range`。范围`P12H` 扫描从管道开始的最后12个小时内修改的所有对象。这覆盖了`range` 在[扫描](#scan) 等级。

### 筛选

使用以下选项`filter` 配置。

选项| 必需的| 类型| 描述
：--- | ：--- | ：--- | ：---
`include_prefix` | 不| 列表| 扫描中包含的S3密钥前缀字符串列表。默认情况下，包含一个存储桶中的所有对象。
`exclude_suffix` | 不| 列表| 扫描中排除的S3键后缀字符串列表。默认情况下，存储桶中没有任何对象被排除在外。

### 调度

选项| 必需的| 类型| 描述
：--- | ：--- | ：--- | ：---
`interval` | 是的| 细绳| 指示每次扫描之间的最小间隔。间隔中的下一次扫描将在最后扫描结束的间隔持续时间以及上一个扫描中的所有对象进行处理后开始。支持ISO 8601符号字符串，例如`PT20.345S` 或者`PT15M`，和符号字符串几秒钟（`60s`）和毫秒（`1600ms`）。
`count` | 不| 整数| 指定将扫描一个水桶多少次。默认为`Integer.MAX_VALUE`。


## 指标

这`s3` 来源包括以下指标：

### 柜台

*`s3ObjectsFailed`：S3对象的数量`s3` 来源未能阅读。
*`s3ObjectsNotFound`：S3对象的数量`s3` 由于S3，来源未能阅读"Not Found" 错误。这些也被计入`s3ObjectsFailed`。
*`s3ObjectsAccessDenied`：S3对象的数量`s3` 源由于一个而无法阅读"Access Denied" 或者"Forbidden" 错误。这些也被计入`s3ObjectsFailed`。
*`s3ObjectsSucceeded`：S3对象的数量`s3` 来源成功阅读。
*`sqsMessagesReceived`：亚马逊SQS消息的数量`s3` 来源。
*`sqsMessagesDeleted`：从队列中删除的Amazon SQS消息的数量`s3` 来源。
*`sqsMessagesFailed`：Amazon SQS消息的数量`s3` 来源无法解析。
*`s3ObjectNoRecordsFound` -- 导致0个记录的S3对象的数量添加到缓冲区中`s3` 来源。
*`sqsMessagesDeleteFailed` -- SQS消息的数量`s3` 源无法从SQS队列中删除。
*`s3ObjectsDeleted` -- S3对象的数量由`s3` 来源。
*`s3ObjectsDeleteFailed` -- S3对象的数量`s3` 源无法删除。

### 计时器

*`s3ObjectReadTimeElapsed`：测量时间的时间`s3` 来源需要执行请求以获取S3对象，解析并将事件写入缓冲区。
*`sqsMessageDelay`：测量从S3创建对象到完全解析对象的时间。

### 分销摘要

*`s3ObjectSizeBytes`：测量S3报告的S3对象的大小`Content-Length`。对于压缩对象，这是压缩大小。
*`s3ObjectProcessedBytes`：测量由`s3` 给定对象的来源。对于压缩对象，这是未压缩的大小。
*`s3ObjectsEvents`：测量S3对象产生的事件数量（有时称为记录）。

## 示例：使用SQS未压缩的日志

以下管道.yaml文件显示用于读取未压缩newline的最小配置-划界日志：

```
source:
  s3:
    notification_type: sqs
    codec:
      newline:
    compression: none
    sqs:
      queue_url: "https://sqs.us-east-1.amazonaws.com/123456789012/MyQueue"
    aws:
      region: "us-east-1"
      sts_role_arn: "arn:aws:iam::123456789012:role/Data-Prepper"
```

## 示例：扫描未压缩的日志

以下管道.yaml文件显示了使用未压缩newline的扫描对象的最小配置-划界日志：

```
source:
  s3:
    codec:
      newline:
    compression: none
    aws:
      region: "us-east-1"
      sts_role_arn: "arn:aws:iam::123456789012:role/Data-Prepper"
    scan:
      start_time: 2023-01-01T00:00:00
      range: "P365D"
      buckets:
        - bucket:
            name: "s3-scan-test"
            filter:
              exclude_suffix:
                - "*.log"
```

